{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJdcrhHjXCSD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coHRGtg0GhvE",
        "outputId": "d0f1cba6-44a7-4085-a6c5-d744d85621b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@markdown ---------------\n",
        "#@markdown ## **⚠️❗ Ejecute esta celda para descargar Shoes dataset❗⚠️**\n",
        "#@markdown ### Esta celda creará la carpeta ```/content/shoes_data```\n",
        "\n",
        "!pip install -qq gdown\n",
        "!gdown -qq \"https://drive.google.com/uc?id=1_fIMm5nPp0BLJZKfkJZ_juRmLpRK4iA0\" -O /shoes_data.zip\n",
        "!mkdir /content/shoes_data/\n",
        "!unzip -qq /shoes_data.zip -d /content/shoes_data\n",
        "!rm -r /shoes_data.zip\n",
        "print (\"Done!\")\n",
        "#@markdown ---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "455fTedilRSj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMb_M3ESU9OK"
      },
      "outputs": [],
      "source": [
        "image_transforms = transforms.Compose([transforms.Resize((64,64), Image.BICUBIC),\n",
        "                                       transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkLxcJqwGhvE"
      },
      "outputs": [],
      "source": [
        "#---- Importar librerias. Incluya acá todas las librerías que requiera\n",
        "train_dataset = datasets.ImageFolder(root= _ , transform = _ )\n",
        "test_dataset = datasets.ImageFolder(root= _ , transform = _ )\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = _ , shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = _ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meL3u08AGhvE"
      },
      "outputs": [],
      "source": [
        "#---- Introduzca su codigo aqui. Puede utilizar cuantas celdas de código considere necesarias\n",
        "\n",
        "# grab a batch from both training and validation dataloader\n",
        "trainBatch = next(iter(train_loader))\n",
        "valBatch = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mheatb_WM0S"
      },
      "outputs": [],
      "source": [
        "print (trainBatch[1].shape, valBatch[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv7K_A2vPxzz"
      },
      "outputs": [],
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d( _ , _ , kernel_size = _ , padding = _ ), nn.MaxPool2d(kernel_size = _ ), nn.ReLU(),\n",
        "    nn.Conv2d( _ , _ , kernel_size = _ , padding = _ ), nn.MaxPool2d(kernel_size = _ ), nn.ReLU(),\n",
        "    nn.Conv2d( _ , _ , kernel_size = _ , padding = _ ), nn.MaxPool2d(kernel_size = _ ), nn.ReLU(),\n",
        "    nn.Conv2d( _ , _ , kernel_size = _ , padding = _ ), nn.MaxPool2d(kernel_size = _ ), nn.ReLU(),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear( _ , _ ), nn.ReLU(),\n",
        "    nn.Linear( _ , _ ), nn.ReLU(),\n",
        "    nn.Linear( _ , _ ), nn.ReLU(),\n",
        "    nn.Linear( _ , _ ), nn.Softmax()\n",
        ")\n",
        "\n",
        "model.cuda()\n",
        "summary(model, input_size=( _ ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfoQQGF6HOmW",
        "outputId": "b98e4956-0646-4987-8079-f9a7a440de93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss = _ \n",
        "optimizer = _ \n",
        "\n",
        "loss.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wr9Nf23DSxcW"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "batch_size = 200\n",
        "losses = []\n",
        "\n",
        "progress = tqdm(range( _ ), ncols=110)\n",
        "\n",
        "for epoch in progress:\n",
        "  #\n",
        "  batch_losses = 0\n",
        "\n",
        "  # for batch_i in range(0, len(X_train) , batch_size):\n",
        "  for batch_i, (batch_X, batch_y) in enumerate(train_loader):\n",
        "    #\n",
        "\n",
        "    # Zero the gradients\n",
        "    _\n",
        "\n",
        "    # Perform forward pass\n",
        "    predictions = _\n",
        "\n",
        "    # Compute loss\n",
        "    batch_loss = loss( _ , _ )\n",
        "\n",
        "    # Perform backward pass\n",
        "    _\n",
        "\n",
        "    # Optimize parameters\n",
        "    _\n",
        "\n",
        "    ## Save stats\n",
        "    batch_losses += batch_loss.item()\n",
        "    \n",
        "\n",
        "  progress.set_description(\"Epoch [%d/%d] [Loss: %f]\" % (epoch, epochs,\n",
        "                                                         batch_loss.item()))\n",
        "\n",
        "  losses.append(batch_losses/(len(train_loader)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTAUMxmfdHEx"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.plot(np.array( _ ))\n",
        "plt.xlabel(\"Epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWCmZ4vQY5Df"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
